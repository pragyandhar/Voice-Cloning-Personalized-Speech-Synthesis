{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Hindi XTTSv2 (Multi-speaker + Speaker Embeddings)\n",
        "This notebook prepares metadata, extracts ECAPA embeddings, then fine-tunes XTTSv2. Run cells in order on GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project: d:\\IMPORTANT\\hindi_voice_cloning_final\n",
            "Data: d:\\IMPORTANT\\hindi_voice_cloning_final\\data\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "PROJ_DIR = os.path.abspath('..')\n",
        "DATA_DIR = os.path.join(PROJ_DIR, 'data')\n",
        "AUDIO_DIR = os.path.join(DATA_DIR, 'audio')\n",
        "META_CSV = os.path.join(DATA_DIR, 'metadata.csv')\n",
        "EMB_OUT = os.path.join(DATA_DIR, 'embeddings.npy')\n",
        "OUT_DIR = os.path.join(PROJ_DIR, 'checkpoints')\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "print('Project:', PROJ_DIR)\n",
        "print('Data:', DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote 0 rows to d:\\IMPORTANT\\hindi_voice_cloning_final\\data\\metadata.csv\n",
            "Saved metadata to d:\\IMPORTANT\\hindi_voice_cloning_final\\data\\metadata.csv\n"
          ]
        }
      ],
      "source": [
        "# Add project root to Python path\n",
        "import sys\n",
        "if PROJ_DIR not in sys.path:\n",
        "\tsys.path.append(PROJ_DIR)\n",
        "\n",
        "# Step 1: Build metadata.csv from JSON\n",
        "# 'scripts' may not be a package; import the module by file path to avoid ModuleNotFoundError\n",
        "import importlib.util, importlib.machinery\n",
        "pm_path = os.path.join(PROJ_DIR, \"scripts\", \"prepare_metadata.py\")\n",
        "spec = importlib.util.spec_from_file_location(\"prepare_metadata\", pm_path)\n",
        "pm = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(pm)\n",
        "\n",
        "json_path = os.path.join(DATA_DIR, 'commonvoice_hindi.json')\n",
        "pm.build(json_path, AUDIO_DIR, META_CSV)\n",
        "print('Saved metadata to', META_CSV)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\IMPORTANT\\hindi_voice_cloning_final\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "d:\\IMPORTANT\\hindi_voice_cloning_final\\scripts\\extract_embeddings.py:4: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
            "  from speechbrain.pretrained import EncoderClassifier\n",
            "d:\\IMPORTANT\\hindi_voice_cloning_final\\venv\\lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved embeddings to d:\\IMPORTANT\\hindi_voice_cloning_final\\data\\embeddings.npy\n",
            "Saved embeddings to d:\\IMPORTANT\\hindi_voice_cloning_final\\data\\embeddings.npy\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Extract speaker embeddings (ECAPA-TDNN)\n",
        "import scripts.extract_embeddings as ex\n",
        "ex.run(META_CSV, AUDIO_DIR, EMB_OUT)\n",
        "print('Saved embeddings to', EMB_OUT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'is_g2p_en_available' from 'transformers.utils' (d:\\IMPORTANT\\hindi_voice_cloning_final\\venv\\lib\\site-packages\\transformers\\utils\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 73\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ======================================================\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Step 1 ‚Äì Imports after patch\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# ======================================================\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer, TrainerArgs\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XttsConfig\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshared_configs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseDatasetConfig\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Xtts\n",
            "File \u001b[1;32md:\\IMPORTANT\\hindi_voice_cloning_final\\venv\\lib\\site-packages\\TTS\\tts\\configs\\xtts_config.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshared_configs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTTSConfig\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XttsArgs, XttsAudioConfig\n\u001b[0;32m      8\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mXttsConfig\u001b[39;00m(BaseTTSConfig):\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Defines parameters for XTTS TTS model.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m        >>> config = XttsConfig()\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "File \u001b[1;32md:\\IMPORTANT\\hindi_voice_cloning_final\\venv\\lib\\site-packages\\TTS\\tts\\models\\xtts.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcoqpit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Coqpit\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhifigan_decoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HifiDecoder\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstream_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_stream_support\n",
            "File \u001b[1;32md:\\IMPORTANT\\hindi_voice_cloning_final\\venv\\lib\\site-packages\\TTS\\tts\\layers\\xtts\\gpt.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT2Config\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt_inference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT2InferenceModel\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlatent_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConditioningEncoder\n",
            "File \u001b[1;32md:\\IMPORTANT\\hindi_voice_cloning_final\\venv\\lib\\site-packages\\transformers\\__init__.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     30\u001b[0m     _LazyModule,\n\u001b[0;32m     31\u001b[0m     is_essentia_available,\n\u001b[0;32m     32\u001b[0m     is_g2p_en_available,\n\u001b[0;32m     33\u001b[0m     is_librosa_available,\n\u001b[0;32m     34\u001b[0m     is_mistral_common_available,\n\u001b[0;32m     35\u001b[0m     is_mlx_available,\n\u001b[0;32m     36\u001b[0m     is_pretty_midi_available,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_available \u001b[38;5;28;01mas\u001b[39;00m is_bitsandbytes_available\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'is_g2p_en_available' from 'transformers.utils' (d:\\IMPORTANT\\hindi_voice_cloning_final\\venv\\lib\\site-packages\\transformers\\utils\\__init__.py)"
          ]
        }
      ],
      "source": [
        "# ==============================================\n",
        "# ‚úÖ HINDI VOICE CLONING TRAINING SCRIPT (XTTS)\n",
        "# Compatible with Coqui-TTS v0.22.0 + Transformers ‚â•4.33.0\n",
        "# Includes full runtime patch for missing imports (jieba + soundfile)\n",
        "# ==============================================\n",
        "\n",
        "import os, sys, time, shutil, subprocess, torch, torch.nn as nn\n",
        "\n",
        "# ======================================================\n",
        "# Step 0 ‚Äì Ensure Dependencies\n",
        "# ======================================================\n",
        "# Ensure a transformers-compatible tokenizers version is installed first,\n",
        "# then install TTS and transformers. Use --upgrade to replace incompatible installs.\n",
        "required_packages = [\n",
        "    \"tokenizers==0.23.0\",\n",
        "    \"TTS==0.22.0\",\n",
        "    \"transformers>=4.33.0\",\n",
        "]\n",
        "for pkg in required_packages:\n",
        "    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", pkg])\n",
        "\n",
        "# ======================================================\n",
        "# üß© Monkey-patch for missing optional imports\n",
        "# ======================================================\n",
        "from importlib import import_module\n",
        "\n",
        "try:\n",
        "    imp_utils = import_module(\"transformers.utils.import_utils\")\n",
        "\n",
        "    # Patch missing helper functions dynamically\n",
        "    if not hasattr(imp_utils, \"is_jieba_available\"):\n",
        "        imp_utils.is_jieba_available = lambda: False\n",
        "        print(\"‚úÖ Patched: added dummy is_jieba_available()\")\n",
        "\n",
        "    # Patch both correct and typo versions for soundfile\n",
        "    if not hasattr(imp_utils, \"is_soundfile_available\"):\n",
        "        imp_utils.is_soundfile_available = lambda: False\n",
        "        print(\"‚úÖ Patched: added dummy is_soundfile_available()\")\n",
        "    if not hasattr(imp_utils, \"is_soundfile_availble\"):\n",
        "        imp_utils.is_soundfile_availble = lambda: False\n",
        "        print(\"‚úÖ Patched: added dummy is_soundfile_availble() (typo)\")\n",
        "    \n",
        "    # Patch missing TPU function\n",
        "    if not hasattr(imp_utils, \"is_torch_tpu_available\"):\n",
        "        imp_utils.is_torch_tpu_available = lambda: False\n",
        "        print(\"‚úÖ Patched: added dummy is_torch_tpu_available()\")\n",
        "        \n",
        "    # Patch missing tf_required function\n",
        "    if not hasattr(imp_utils, \"tf_required\"):\n",
        "        def tf_required(func):\n",
        "            def wrapper(*args, **kwargs):\n",
        "                return func(*args, **kwargs)\n",
        "            return wrapper\n",
        "        imp_utils.tf_required = tf_required\n",
        "        print(\"‚úÖ Patched: added dummy tf_required decorator\")\n",
        "\n",
        "    # Patch missing torch_required function\n",
        "    if not hasattr(imp_utils, \"torch_required\"):\n",
        "        def torch_required(func):\n",
        "            def wrapper(*args, **kwargs):\n",
        "                return func(*args, **kwargs)\n",
        "            return wrapper\n",
        "        imp_utils.torch_required = torch_required\n",
        "        print(\"‚úÖ Patched: added dummy torch_required decorator\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Transformer patch failed: {e}\")\n",
        "\n",
        "# ======================================================\n",
        "# Step 1 ‚Äì Imports after patch\n",
        "# ======================================================\n",
        "from trainer import Trainer, TrainerArgs\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.config.shared_configs import BaseDatasetConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "\n",
        "# ======================================================\n",
        "# Step 2 ‚Äì Paths\n",
        "# ======================================================\n",
        "DATA_DIR = r\"D:\\IMPORTANT\\hindi_voice_cloning_final\\dataset\"\n",
        "META_CSV = os.path.join(DATA_DIR, \"metadata.csv\")\n",
        "OUT_DIR = r\"D:\\IMPORTANT\\hindi_voice_cloning_final\\output\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Clean stale .lock or log files\n",
        "for root, _, files in os.walk(OUT_DIR):\n",
        "    for f in files:\n",
        "        if \"trainer_0_log\" in f.lower() or \".lock\" in f.lower():\n",
        "            try:\n",
        "                os.remove(os.path.join(root, f))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "# Unique folder\n",
        "timestamp = time.strftime(\"%b-%d-%Y_%I-%M-%S%p\")\n",
        "RUN_DIR = os.path.join(OUT_DIR, f\"hindi_xtts_final-{timestamp}\")\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "print(f\"üßæ Logs and checkpoints will be saved in: {RUN_DIR}\")\n",
        "\n",
        "# ======================================================\n",
        "# Step 3 ‚Äì Dataset Configuration\n",
        "# ======================================================\n",
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\",\n",
        "    meta_file_train=META_CSV,\n",
        "    path=DATA_DIR,\n",
        ")\n",
        "\n",
        "# ======================================================\n",
        "# Step 4 ‚Äì XTTS Model Configuration\n",
        "# ======================================================\n",
        "config = XttsConfig()\n",
        "config.audio.resample = 16000\n",
        "config.languages = [\"hi\"]\n",
        "config.enable_eos_bos_chars = True\n",
        "config.text_cleaner = \"multilingual_cleaners\"\n",
        "config.model_args.num_chars = 256\n",
        "config.dataset_config = dataset_config\n",
        "\n",
        "config.run_name = \"hindi_xtts_final\"\n",
        "config.output_path = RUN_DIR\n",
        "config.batch_size = 8\n",
        "config.epochs = 8\n",
        "config.test_delay_epochs = 1\n",
        "config.num_loader_workers = 4\n",
        "config.eval_split_max_size = 100\n",
        "config.save_step = 500\n",
        "config.print_step = 25\n",
        "config.save_checkpoints = True\n",
        "config.use_phonemes = False\n",
        "config.mixed_precision = True\n",
        "config.grad_clip = 1.0\n",
        "\n",
        "# ======================================================\n",
        "# Step 5 ‚Äì Initialize Model\n",
        "# ======================================================\n",
        "print(\"üîÑ Initializing XTTS model for Hindi training...\")\n",
        "model = Xtts.init_from_config(config)\n",
        "\n",
        "# Fallback for missing criterion (Tacotron2Loss)\n",
        "class Tacotron2Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "    def forward(self, pred, target):\n",
        "        return self.mse(pred, target)\n",
        "\n",
        "if not hasattr(model, \"get_criterion\"):\n",
        "    model.get_criterion = lambda: Tacotron2Loss()\n",
        "\n",
        "# ======================================================\n",
        "# Step 6 ‚Äì Trainer Setup\n",
        "# ======================================================\n",
        "try:\n",
        "    args = TrainerArgs()\n",
        "except Exception:\n",
        "    class DummyArgs:\n",
        "        def parse_args(self, *a, **kw): return self\n",
        "    args = DummyArgs()\n",
        "\n",
        "trainer_log = os.path.join(RUN_DIR, \"trainer_0_log.txt\")\n",
        "if os.path.exists(trainer_log):\n",
        "    try:\n",
        "        os.remove(trainer_log)\n",
        "    except PermissionError:\n",
        "        trainer_log = trainer_log.replace(\".txt\", \"_alt.txt\")\n",
        "        print(f\"‚ö†Ô∏è Log file locked, switching to {trainer_log}\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    args=args,\n",
        "    config=config,\n",
        "    output_path=RUN_DIR,\n",
        "    model=model,\n",
        ")\n",
        "\n",
        "# Refresh log file safely\n",
        "if hasattr(trainer, \"log_file\") and trainer.log_file:\n",
        "    try:\n",
        "        trainer.log_file.close()\n",
        "    except Exception:\n",
        "        pass\n",
        "    trainer.log_file = open(trainer_log, \"a\", encoding=\"utf-8\")\n",
        "\n",
        "# ======================================================\n",
        "# Step 7 ‚Äì Start Training\n",
        "# ======================================================\n",
        "print(\"üöÄ Starting XTTS training for Hindi voice cloning...\")\n",
        "\n",
        "try:\n",
        "    trainer.fit()\n",
        "except PermissionError as e:\n",
        "    print(f\"‚ö†Ô∏è PermissionError: {e}\")\n",
        "    print(\"‚è≥ Retrying after releasing handles...\")\n",
        "    time.sleep(5)\n",
        "    trainer.log_file = open(trainer_log.replace(\".txt\", \"_retry.txt\"), \"a\", encoding=\"utf-8\")\n",
        "    trainer.fit()\n",
        "\n",
        "print(f\"‚úÖ Training complete! Checkpoints saved in: {RUN_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Quick inference example (after training)\n",
        "from TTS.api import TTS\n",
        "model_file = os.path.join(OUT_DIR, 'best_model.pth')\n",
        "if os.path.exists(model_file):\n",
        "    tts = TTS(model_path=model_file, gpu=True)\n",
        "    # load first embedding and synthesize using it\n",
        "    import numpy as np\n",
        "    embobj = np.load(EMB_OUT, allow_pickle=True).item()\n",
        "    emb = embobj['embeddings'][0]\n",
        "    tts.tts_to_file(text='‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ø‡§π ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ï‡§æ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§π‡•à‡•§', speaker_embeddings=emb, file_path=os.path.join(PROJ_DIR, 'test_output.wav'))\n",
        "    print('Saved test_output.wav')\n",
        "else:\n",
        "    print('No model found yet. Train first or point to a model path.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
